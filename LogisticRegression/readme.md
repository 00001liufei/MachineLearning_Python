逻辑回归（logistics regression）
=========

[![MIT license](https://img.shields.io/dub/l/vibe-d.svg)](https://github.com/lawlite19/MachineLearning_Python/blob/master/LICENSE)

## 目录
* [一、分类和回归的区别](#一分类和回归的区别)
* [二、逻辑回归](#二逻辑回归)
	* [1、用回归方法进行分类](#1用回归方法进行分类)

## 一、分类和回归的区别

<br/>　　我们可以按照任务的种类,将任务分为回归任务和分类任务.那这两者的区别是什么呢?
按照较官方些的说法,输入变量与输出变量均为连续变量的预测问题是回归问题,输出变量为有限个离散变量的预测问题称为分类问题.
<br/>　　通俗一点讲,我们要预测的结果是一个数,比如要通过一个人的饮食预测一个人的体重,体重的值可以有无限多个,
有的人50kg,有的人51kg,在50和51之间也有无限多个数.这种预测结果是某一个确定数,而具体是哪个数有无限多种可能,
我们会训练出一个模型,传入参数后得到这个确定的数,这类问题我们称为回归问题。
预测的这个变量(体重)因为有无限多种可能,在数轴上是连续的,所以我们称这种变量为连续变量.
<br/>　　我们要预测一个人身体健康或者不健康,预测会得癌症或者不会得癌症,预测他是水瓶座,天蝎座还是射手座,
这种结果只有几个值或者多个值的问题,我们可以把每个值都当做一类,预测对象到底属于哪一类。
这样的问题称为分类问题。如果一个分类问题的结果只有两个,比如"是"和"不是"两个结果,
我们把结果为"是"的样例数据称为"正例",讲结果为"不是"的样例数据称为"负例",对应的,这种结果的变量称为离散型变量。

## 二、逻辑回归
<br/>　　从名字来理解逻辑回归.在逻辑回归中,逻辑一词是logistics的音译字,并不是因为这个算法是突出逻辑的特性.
<br/>　　至于回归,我们前一段讲到回归任务是结果为连续型变量的任务,logistics regression是用来做分类任务的,
为什么叫回归呢?那我们是不是可以假设,逻辑回归就是用回归的办法来做分类的呢.

### 1、用回归方法进行分类

<br/>　　假设刚刚的思路是正确的,逻辑回归就是在用回归的办法做分类任务,那有什么办法可以做到呢,
此时我们就先考虑最简单的二分类,结果是正例或者负例的任务.

<br/>　　按照多元线性回归的思路,我们可以先对这个任务进行线性回归,学习出这个事情结果的规律,
比如根据人的饮食,作息,工作和生存环境等条件预测一个人"有"或者"没有"得恶性肿瘤,可以先通过回归任务来预测人体内肿瘤的大小,
取一个平均值作为阈值,假如平均值为y,肿瘤大小超过y为恶性肿瘤,无肿瘤或大小小于y的,为非恶性.
这样通过线性回归加设定阈值的办法,就可以完成一个简单的二分类任务.如下图:

![enter description here][1]

<br/>　　上图中x轴为肿瘤大小，粉色线为回归得到的函数![{h_\theta}(x)](http://chart.apis.google.com/chart?cht=tx&chs=1x0&chf=bg,s,FFFFFF00&chco=000000&chl=J%28%5Ctheta%20%29%20%3D%20%5Cfrac%7B1%7D%7B%7B2%7B%5Ctext%7Bm%7D%7D%7D%7D%5Csum%5Climits_%7Bi%20%3D%201%7D%5Em%20%7B%7B%7B%28%7Bh_%5Ctheta%20%7D%28%7Bx%5E%7B%28i%29%7D%7D%29%20-%20%7By%5E%7B%28i%29%7D%7D%29%7D%5E2%7D%7D%20)
，












----------------------------------


  [1]: ../images/logisticsRegression_04.jpg "logisticsRegression_04.jpg"



















